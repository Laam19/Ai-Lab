{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Air_+Polution_Using_neural_network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "teIU3I8Rt828"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import seaborn as sns\r\n",
        "import io\r\n",
        "sns.set()\r\n",
        "from matplotlib import rcParams"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "Ly8gQ29weXJpZ2h0IDIwMTcgR29vZ2xlIExMQwovLwovLyBMaWNlbnNlZCB1bmRlciB0aGUgQXBhY2hlIExpY2Vuc2UsIFZlcnNpb24gMi4wICh0aGUgIkxpY2Vuc2UiKTsKLy8geW91IG1heSBub3QgdXNlIHRoaXMgZmlsZSBleGNlcHQgaW4gY29tcGxpYW5jZSB3aXRoIHRoZSBMaWNlbnNlLgovLyBZb3UgbWF5IG9idGFpbiBhIGNvcHkgb2YgdGhlIExpY2Vuc2UgYXQKLy8KLy8gICAgICBodHRwOi8vd3d3LmFwYWNoZS5vcmcvbGljZW5zZXMvTElDRU5TRS0yLjAKLy8KLy8gVW5sZXNzIHJlcXVpcmVkIGJ5IGFwcGxpY2FibGUgbGF3IG9yIGFncmVlZCB0byBpbiB3cml0aW5nLCBzb2Z0d2FyZQovLyBkaXN0cmlidXRlZCB1bmRlciB0aGUgTGljZW5zZSBpcyBkaXN0cmlidXRlZCBvbiBhbiAiQVMgSVMiIEJBU0lTLAovLyBXSVRIT1VUIFdBUlJBTlRJRVMgT1IgQ09ORElUSU9OUyBPRiBBTlkgS0lORCwgZWl0aGVyIGV4cHJlc3Mgb3IgaW1wbGllZC4KLy8gU2VlIHRoZSBMaWNlbnNlIGZvciB0aGUgc3BlY2lmaWMgbGFuZ3VhZ2UgZ292ZXJuaW5nIHBlcm1pc3Npb25zIGFuZAovLyBsaW1pdGF0aW9ucyB1bmRlciB0aGUgTGljZW5zZS4KCi8qKgogKiBAZmlsZW92ZXJ2aWV3IEhlbHBlcnMgZm9yIGdvb2dsZS5jb2xhYiBQeXRob24gbW9kdWxlLgogKi8KKGZ1bmN0aW9uKHNjb3BlKSB7CmZ1bmN0aW9uIHNwYW4odGV4dCwgc3R5bGVBdHRyaWJ1dGVzID0ge30pIHsKICBjb25zdCBlbGVtZW50ID0gZG9jdW1lbnQuY3JlYXRlRWxlbWVudCgnc3BhbicpOwogIGVsZW1lbnQudGV4dENvbnRlbnQgPSB0ZXh0OwogIGZvciAoY29uc3Qga2V5IG9mIE9iamVjdC5rZXlzKHN0eWxlQXR0cmlidXRlcykpIHsKICAgIGVsZW1lbnQuc3R5bGVba2V5XSA9IHN0eWxlQXR0cmlidXRlc1trZXldOwogIH0KICByZXR1cm4gZWxlbWVudDsKfQoKLy8gTWF4IG51bWJlciBvZiBieXRlcyB3aGljaCB3aWxsIGJlIHVwbG9hZGVkIGF0IGEgdGltZS4KY29uc3QgTUFYX1BBWUxPQURfU0laRSA9IDEwMCAqIDEwMjQ7CgpmdW5jdGlvbiBfdXBsb2FkRmlsZXMoaW5wdXRJZCwgb3V0cHV0SWQpIHsKICBjb25zdCBzdGVwcyA9IHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCk7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICAvLyBDYWNoZSBzdGVwcyBvbiB0aGUgb3V0cHV0RWxlbWVudCB0byBtYWtlIGl0IGF2YWlsYWJsZSBmb3IgdGhlIG5leHQgY2FsbAogIC8vIHRvIHVwbG9hZEZpbGVzQ29udGludWUgZnJvbSBQeXRob24uCiAgb3V0cHV0RWxlbWVudC5zdGVwcyA9IHN0ZXBzOwoKICByZXR1cm4gX3VwbG9hZEZpbGVzQ29udGludWUob3V0cHV0SWQpOwp9CgovLyBUaGlzIGlzIHJvdWdobHkgYW4gYXN5bmMgZ2VuZXJhdG9yIChub3Qgc3VwcG9ydGVkIGluIHRoZSBicm93c2VyIHlldCksCi8vIHdoZXJlIHRoZXJlIGFyZSBtdWx0aXBsZSBhc3luY2hyb25vdXMgc3RlcHMgYW5kIHRoZSBQeXRob24gc2lkZSBpcyBnb2luZwovLyB0byBwb2xsIGZvciBjb21wbGV0aW9uIG9mIGVhY2ggc3RlcC4KLy8gVGhpcyB1c2VzIGEgUHJvbWlzZSB0byBibG9jayB0aGUgcHl0aG9uIHNpZGUgb24gY29tcGxldGlvbiBvZiBlYWNoIHN0ZXAsCi8vIHRoZW4gcGFzc2VzIHRoZSByZXN1bHQgb2YgdGhlIHByZXZpb3VzIHN0ZXAgYXMgdGhlIGlucHV0IHRvIHRoZSBuZXh0IHN0ZXAuCmZ1bmN0aW9uIF91cGxvYWRGaWxlc0NvbnRpbnVlKG91dHB1dElkKSB7CiAgY29uc3Qgb3V0cHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKG91dHB1dElkKTsKICBjb25zdCBzdGVwcyA9IG91dHB1dEVsZW1lbnQuc3RlcHM7CgogIGNvbnN0IG5leHQgPSBzdGVwcy5uZXh0KG91dHB1dEVsZW1lbnQubGFzdFByb21pc2VWYWx1ZSk7CiAgcmV0dXJuIFByb21pc2UucmVzb2x2ZShuZXh0LnZhbHVlLnByb21pc2UpLnRoZW4oKHZhbHVlKSA9PiB7CiAgICAvLyBDYWNoZSB0aGUgbGFzdCBwcm9taXNlIHZhbHVlIHRvIG1ha2UgaXQgYXZhaWxhYmxlIHRvIHRoZSBuZXh0CiAgICAvLyBzdGVwIG9mIHRoZSBnZW5lcmF0b3IuCiAgICBvdXRwdXRFbGVtZW50Lmxhc3RQcm9taXNlVmFsdWUgPSB2YWx1ZTsKICAgIHJldHVybiBuZXh0LnZhbHVlLnJlc3BvbnNlOwogIH0pOwp9CgovKioKICogR2VuZXJhdG9yIGZ1bmN0aW9uIHdoaWNoIGlzIGNhbGxlZCBiZXR3ZWVuIGVhY2ggYXN5bmMgc3RlcCBvZiB0aGUgdXBsb2FkCiAqIHByb2Nlc3MuCiAqIEBwYXJhbSB7c3RyaW5nfSBpbnB1dElkIEVsZW1lbnQgSUQgb2YgdGhlIGlucHV0IGZpbGUgcGlja2VyIGVsZW1lbnQuCiAqIEBwYXJhbSB7c3RyaW5nfSBvdXRwdXRJZCBFbGVtZW50IElEIG9mIHRoZSBvdXRwdXQgZGlzcGxheS4KICogQHJldHVybiB7IUl0ZXJhYmxlPCFPYmplY3Q+fSBJdGVyYWJsZSBvZiBuZXh0IHN0ZXBzLgogKi8KZnVuY3Rpb24qIHVwbG9hZEZpbGVzU3RlcChpbnB1dElkLCBvdXRwdXRJZCkgewogIGNvbnN0IGlucHV0RWxlbWVudCA9IGRvY3VtZW50LmdldEVsZW1lbnRCeUlkKGlucHV0SWQpOwogIGlucHV0RWxlbWVudC5kaXNhYmxlZCA9IGZhbHNlOwoKICBjb25zdCBvdXRwdXRFbGVtZW50ID0gZG9jdW1lbnQuZ2V0RWxlbWVudEJ5SWQob3V0cHV0SWQpOwogIG91dHB1dEVsZW1lbnQuaW5uZXJIVE1MID0gJyc7CgogIGNvbnN0IHBpY2tlZFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgaW5wdXRFbGVtZW50LmFkZEV2ZW50TGlzdGVuZXIoJ2NoYW5nZScsIChlKSA9PiB7CiAgICAgIHJlc29sdmUoZS50YXJnZXQuZmlsZXMpOwogICAgfSk7CiAgfSk7CgogIGNvbnN0IGNhbmNlbCA9IGRvY3VtZW50LmNyZWF0ZUVsZW1lbnQoJ2J1dHRvbicpOwogIGlucHV0RWxlbWVudC5wYXJlbnRFbGVtZW50LmFwcGVuZENoaWxkKGNhbmNlbCk7CiAgY2FuY2VsLnRleHRDb250ZW50ID0gJ0NhbmNlbCB1cGxvYWQnOwogIGNvbnN0IGNhbmNlbFByb21pc2UgPSBuZXcgUHJvbWlzZSgocmVzb2x2ZSkgPT4gewogICAgY2FuY2VsLm9uY2xpY2sgPSAoKSA9PiB7CiAgICAgIHJlc29sdmUobnVsbCk7CiAgICB9OwogIH0pOwoKICAvLyBXYWl0IGZvciB0aGUgdXNlciB0byBwaWNrIHRoZSBmaWxlcy4KICBjb25zdCBmaWxlcyA9IHlpZWxkIHsKICAgIHByb21pc2U6IFByb21pc2UucmFjZShbcGlja2VkUHJvbWlzZSwgY2FuY2VsUHJvbWlzZV0pLAogICAgcmVzcG9uc2U6IHsKICAgICAgYWN0aW9uOiAnc3RhcnRpbmcnLAogICAgfQogIH07CgogIGNhbmNlbC5yZW1vdmUoKTsKCiAgLy8gRGlzYWJsZSB0aGUgaW5wdXQgZWxlbWVudCBzaW5jZSBmdXJ0aGVyIHBpY2tzIGFyZSBub3QgYWxsb3dlZC4KICBpbnB1dEVsZW1lbnQuZGlzYWJsZWQgPSB0cnVlOwoKICBpZiAoIWZpbGVzKSB7CiAgICByZXR1cm4gewogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbXBsZXRlJywKICAgICAgfQogICAgfTsKICB9CgogIGZvciAoY29uc3QgZmlsZSBvZiBmaWxlcykgewogICAgY29uc3QgbGkgPSBkb2N1bWVudC5jcmVhdGVFbGVtZW50KCdsaScpOwogICAgbGkuYXBwZW5kKHNwYW4oZmlsZS5uYW1lLCB7Zm9udFdlaWdodDogJ2JvbGQnfSkpOwogICAgbGkuYXBwZW5kKHNwYW4oCiAgICAgICAgYCgke2ZpbGUudHlwZSB8fCAnbi9hJ30pIC0gJHtmaWxlLnNpemV9IGJ5dGVzLCBgICsKICAgICAgICBgbGFzdCBtb2RpZmllZDogJHsKICAgICAgICAgICAgZmlsZS5sYXN0TW9kaWZpZWREYXRlID8gZmlsZS5sYXN0TW9kaWZpZWREYXRlLnRvTG9jYWxlRGF0ZVN0cmluZygpIDoKICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgICAgJ24vYSd9IC0gYCkpOwogICAgY29uc3QgcGVyY2VudCA9IHNwYW4oJzAlIGRvbmUnKTsKICAgIGxpLmFwcGVuZENoaWxkKHBlcmNlbnQpOwoKICAgIG91dHB1dEVsZW1lbnQuYXBwZW5kQ2hpbGQobGkpOwoKICAgIGNvbnN0IGZpbGVEYXRhUHJvbWlzZSA9IG5ldyBQcm9taXNlKChyZXNvbHZlKSA9PiB7CiAgICAgIGNvbnN0IHJlYWRlciA9IG5ldyBGaWxlUmVhZGVyKCk7CiAgICAgIHJlYWRlci5vbmxvYWQgPSAoZSkgPT4gewogICAgICAgIHJlc29sdmUoZS50YXJnZXQucmVzdWx0KTsKICAgICAgfTsKICAgICAgcmVhZGVyLnJlYWRBc0FycmF5QnVmZmVyKGZpbGUpOwogICAgfSk7CiAgICAvLyBXYWl0IGZvciB0aGUgZGF0YSB0byBiZSByZWFkeS4KICAgIGxldCBmaWxlRGF0YSA9IHlpZWxkIHsKICAgICAgcHJvbWlzZTogZmlsZURhdGFQcm9taXNlLAogICAgICByZXNwb25zZTogewogICAgICAgIGFjdGlvbjogJ2NvbnRpbnVlJywKICAgICAgfQogICAgfTsKCiAgICAvLyBVc2UgYSBjaHVua2VkIHNlbmRpbmcgdG8gYXZvaWQgbWVzc2FnZSBzaXplIGxpbWl0cy4gU2VlIGIvNjIxMTU2NjAuCiAgICBsZXQgcG9zaXRpb24gPSAwOwogICAgd2hpbGUgKHBvc2l0aW9uIDwgZmlsZURhdGEuYnl0ZUxlbmd0aCkgewogICAgICBjb25zdCBsZW5ndGggPSBNYXRoLm1pbihmaWxlRGF0YS5ieXRlTGVuZ3RoIC0gcG9zaXRpb24sIE1BWF9QQVlMT0FEX1NJWkUpOwogICAgICBjb25zdCBjaHVuayA9IG5ldyBVaW50OEFycmF5KGZpbGVEYXRhLCBwb3NpdGlvbiwgbGVuZ3RoKTsKICAgICAgcG9zaXRpb24gKz0gbGVuZ3RoOwoKICAgICAgY29uc3QgYmFzZTY0ID0gYnRvYShTdHJpbmcuZnJvbUNoYXJDb2RlLmFwcGx5KG51bGwsIGNodW5rKSk7CiAgICAgIHlpZWxkIHsKICAgICAgICByZXNwb25zZTogewogICAgICAgICAgYWN0aW9uOiAnYXBwZW5kJywKICAgICAgICAgIGZpbGU6IGZpbGUubmFtZSwKICAgICAgICAgIGRhdGE6IGJhc2U2NCwKICAgICAgICB9LAogICAgICB9OwogICAgICBwZXJjZW50LnRleHRDb250ZW50ID0KICAgICAgICAgIGAke01hdGgucm91bmQoKHBvc2l0aW9uIC8gZmlsZURhdGEuYnl0ZUxlbmd0aCkgKiAxMDApfSUgZG9uZWA7CiAgICB9CiAgfQoKICAvLyBBbGwgZG9uZS4KICB5aWVsZCB7CiAgICByZXNwb25zZTogewogICAgICBhY3Rpb246ICdjb21wbGV0ZScsCiAgICB9CiAgfTsKfQoKc2NvcGUuZ29vZ2xlID0gc2NvcGUuZ29vZ2xlIHx8IHt9OwpzY29wZS5nb29nbGUuY29sYWIgPSBzY29wZS5nb29nbGUuY29sYWIgfHwge307CnNjb3BlLmdvb2dsZS5jb2xhYi5fZmlsZXMgPSB7CiAgX3VwbG9hZEZpbGVzLAogIF91cGxvYWRGaWxlc0NvbnRpbnVlLAp9Owp9KShzZWxmKTsK",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "0I_rNPxIuX6z",
        "outputId": "38b20179-4e0d-4a17-ff33-72d60523d483"
      },
      "source": [
        "from google.colab import files \r\n",
        "  \r\n",
        "  \r\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8da601f6-6a64-48d5-a75a-7ece230002a1\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8da601f6-6a64-48d5-a75a-7ece230002a1\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving Weather Data.csv to Weather Data (1).csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "dmuGtepBujTR",
        "outputId": "1fa344f5-50b5-4747-add1-b5d6b933cfe3"
      },
      "source": [
        "data = pd.read_csv(io.BytesIO(uploaded['Weather Data.csv'])) \r\n",
        "data.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>T</th>\n",
              "      <th>TM</th>\n",
              "      <th>Tm</th>\n",
              "      <th>SLP</th>\n",
              "      <th>H</th>\n",
              "      <th>VV</th>\n",
              "      <th>V</th>\n",
              "      <th>VM</th>\n",
              "      <th>PM 2.5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>7.4</td>\n",
              "      <td>9.8</td>\n",
              "      <td>4.8</td>\n",
              "      <td>1017.6</td>\n",
              "      <td>93.0</td>\n",
              "      <td>0.5</td>\n",
              "      <td>4.3</td>\n",
              "      <td>9.4</td>\n",
              "      <td>219.720833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>7.8</td>\n",
              "      <td>12.7</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1018.5</td>\n",
              "      <td>87.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.4</td>\n",
              "      <td>11.1</td>\n",
              "      <td>182.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.7</td>\n",
              "      <td>13.4</td>\n",
              "      <td>2.4</td>\n",
              "      <td>1019.4</td>\n",
              "      <td>82.0</td>\n",
              "      <td>0.6</td>\n",
              "      <td>4.8</td>\n",
              "      <td>11.1</td>\n",
              "      <td>154.037500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>8.6</td>\n",
              "      <td>15.5</td>\n",
              "      <td>3.3</td>\n",
              "      <td>1018.7</td>\n",
              "      <td>72.0</td>\n",
              "      <td>0.8</td>\n",
              "      <td>8.1</td>\n",
              "      <td>20.6</td>\n",
              "      <td>223.208333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>12.4</td>\n",
              "      <td>20.9</td>\n",
              "      <td>4.4</td>\n",
              "      <td>1017.3</td>\n",
              "      <td>61.0</td>\n",
              "      <td>1.3</td>\n",
              "      <td>8.7</td>\n",
              "      <td>22.2</td>\n",
              "      <td>200.645833</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      T    TM   Tm     SLP     H   VV    V    VM      PM 2.5\n",
              "0   7.4   9.8  4.8  1017.6  93.0  0.5  4.3   9.4  219.720833\n",
              "1   7.8  12.7  4.4  1018.5  87.0  0.6  4.4  11.1  182.187500\n",
              "2   6.7  13.4  2.4  1019.4  82.0  0.6  4.8  11.1  154.037500\n",
              "3   8.6  15.5  3.3  1018.7  72.0  0.8  8.1  20.6  223.208333\n",
              "4  12.4  20.9  4.4  1017.3  61.0  1.3  8.7  22.2  200.645833"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvHE9VPfu137",
        "outputId": "6dab9a9d-62ae-4dfb-a441-30f0b7c31a68"
      },
      "source": [
        "data.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1093 entries, 0 to 1092\n",
            "Data columns (total 9 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   T       1093 non-null   float64\n",
            " 1   TM      1093 non-null   float64\n",
            " 2   Tm      1093 non-null   float64\n",
            " 3   SLP     1093 non-null   float64\n",
            " 4   H       1093 non-null   float64\n",
            " 5   VV      1093 non-null   float64\n",
            " 6   V       1093 non-null   float64\n",
            " 7   VM      1093 non-null   float64\n",
            " 8   PM 2.5  1092 non-null   float64\n",
            "dtypes: float64(9)\n",
            "memory usage: 77.0 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jn0FodKu8rh"
      },
      "source": [
        "data.fillna(method='ffill', inplace = True)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAs3w2nkuo3o"
      },
      "source": [
        "\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "X = data[['T', 'TM', 'Tm', 'SLP', 'H', 'VV', 'V', 'VM']]\r\n",
        "y = data['PM 2.5']\r\n",
        "\r\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.10, random_state = 42)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6nnD2-SvFUr"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\r\n",
        "from tensorflow.keras.layers import Dense, Activation\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IoJr1h5HvIwp"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(19,activation='relu'))\r\n",
        "model.add(Dense(1))\r\n",
        "model.compile(optimizer='Adam',loss='mse')\r\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1iRo12LvL5h",
        "outputId": "f9303a83-4fcc-487b-d9df-1af4c7cd9700"
      },
      "source": [
        "model.fit(x=X_train,y=y_train,\r\n",
        "          validation_data=(X_val,y_val),\r\n",
        "          batch_size=128,epochs=400)\r\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/400\n",
            "8/8 [==============================] - 1s 63ms/step - loss: 11250.3517 - val_loss: 9019.7725\n",
            "Epoch 2/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 8071.4458 - val_loss: 7302.8755\n",
            "Epoch 3/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 7073.2475 - val_loss: 7379.0254\n",
            "Epoch 4/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 7084.9155 - val_loss: 7343.1807\n",
            "Epoch 5/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 6873.3078 - val_loss: 7275.3022\n",
            "Epoch 6/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6903.0472 - val_loss: 7195.1226\n",
            "Epoch 7/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6795.4794 - val_loss: 7168.0942\n",
            "Epoch 8/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6919.3185 - val_loss: 7156.8027\n",
            "Epoch 9/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6794.9451 - val_loss: 7116.0635\n",
            "Epoch 10/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 7022.2668 - val_loss: 7080.9736\n",
            "Epoch 11/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6823.2754 - val_loss: 7071.5117\n",
            "Epoch 12/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6639.3233 - val_loss: 7010.3125\n",
            "Epoch 13/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6713.1987 - val_loss: 6965.9648\n",
            "Epoch 14/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 6828.5002 - val_loss: 6967.4282\n",
            "Epoch 15/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6436.6664 - val_loss: 6867.8115\n",
            "Epoch 16/400\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 6652.9741 - val_loss: 6820.7007\n",
            "Epoch 17/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6216.4104 - val_loss: 6743.8184\n",
            "Epoch 18/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6226.7144 - val_loss: 6667.3042\n",
            "Epoch 19/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6006.8477 - val_loss: 6582.9370\n",
            "Epoch 20/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6042.2685 - val_loss: 6508.1499\n",
            "Epoch 21/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6076.9529 - val_loss: 6383.6631\n",
            "Epoch 22/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 6478.2018 - val_loss: 6343.2915\n",
            "Epoch 23/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6666.7180 - val_loss: 6176.8970\n",
            "Epoch 24/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6136.8888 - val_loss: 6115.8916\n",
            "Epoch 25/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6075.4283 - val_loss: 5890.0996\n",
            "Epoch 26/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 6012.5598 - val_loss: 5986.7949\n",
            "Epoch 27/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5759.3838 - val_loss: 5592.8340\n",
            "Epoch 28/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 5471.7007 - val_loss: 5481.3320\n",
            "Epoch 29/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5549.7225 - val_loss: 5346.7549\n",
            "Epoch 30/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5149.7127 - val_loss: 5105.9697\n",
            "Epoch 31/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4865.9666 - val_loss: 4957.0972\n",
            "Epoch 32/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5270.0327 - val_loss: 4979.3936\n",
            "Epoch 33/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 5365.8798 - val_loss: 4670.9990\n",
            "Epoch 34/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4632.6160 - val_loss: 4589.6538\n",
            "Epoch 35/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4964.4813 - val_loss: 4601.8413\n",
            "Epoch 36/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4593.7882 - val_loss: 4345.8164\n",
            "Epoch 37/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4662.0979 - val_loss: 4203.5273\n",
            "Epoch 38/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4279.6185 - val_loss: 4107.0918\n",
            "Epoch 39/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4731.6440 - val_loss: 4224.8872\n",
            "Epoch 40/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4496.6860 - val_loss: 4357.9937\n",
            "Epoch 41/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4410.3964 - val_loss: 3920.7090\n",
            "Epoch 42/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4305.4483 - val_loss: 3872.8787\n",
            "Epoch 43/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 4280.2845 - val_loss: 3851.4907\n",
            "Epoch 44/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4333.5923 - val_loss: 4196.7954\n",
            "Epoch 45/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4640.9076 - val_loss: 4264.4966\n",
            "Epoch 46/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4674.7027 - val_loss: 3711.4712\n",
            "Epoch 47/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4177.0798 - val_loss: 3700.2727\n",
            "Epoch 48/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4043.0931 - val_loss: 3744.4624\n",
            "Epoch 49/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3925.7643 - val_loss: 3698.8557\n",
            "Epoch 50/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3954.0760 - val_loss: 3602.5715\n",
            "Epoch 51/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4126.1850 - val_loss: 3606.1670\n",
            "Epoch 52/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4046.3238 - val_loss: 3864.1897\n",
            "Epoch 53/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3906.6817 - val_loss: 3528.6755\n",
            "Epoch 54/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4259.8202 - val_loss: 3574.7681\n",
            "Epoch 55/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4097.0657 - val_loss: 3637.2705\n",
            "Epoch 56/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3955.1749 - val_loss: 3510.6135\n",
            "Epoch 57/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4259.2625 - val_loss: 3581.6296\n",
            "Epoch 58/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4153.0335 - val_loss: 3942.4197\n",
            "Epoch 59/400\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3933.7156 - val_loss: 3445.7434\n",
            "Epoch 60/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4149.8359 - val_loss: 3546.8337\n",
            "Epoch 61/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3747.3498 - val_loss: 3618.8159\n",
            "Epoch 62/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3852.9939 - val_loss: 3411.0244\n",
            "Epoch 63/400\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 4078.0824 - val_loss: 3375.7324\n",
            "Epoch 64/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3926.6861 - val_loss: 3511.3118\n",
            "Epoch 65/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4074.5149 - val_loss: 3690.9744\n",
            "Epoch 66/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4053.4792 - val_loss: 3276.5125\n",
            "Epoch 67/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3984.1672 - val_loss: 3308.7708\n",
            "Epoch 68/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3772.8029 - val_loss: 3513.1069\n",
            "Epoch 69/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3704.0457 - val_loss: 3298.0854\n",
            "Epoch 70/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3835.2131 - val_loss: 3424.1357\n",
            "Epoch 71/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3746.4489 - val_loss: 3404.2012\n",
            "Epoch 72/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3945.5585 - val_loss: 3652.4426\n",
            "Epoch 73/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3883.6005 - val_loss: 3243.6006\n",
            "Epoch 74/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3728.1708 - val_loss: 3468.1506\n",
            "Epoch 75/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3736.6489 - val_loss: 3421.8831\n",
            "Epoch 76/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3758.5965 - val_loss: 3229.9155\n",
            "Epoch 77/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3913.8979 - val_loss: 3249.8616\n",
            "Epoch 78/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3649.3684 - val_loss: 3218.5874\n",
            "Epoch 79/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3597.1620 - val_loss: 3182.9756\n",
            "Epoch 80/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3819.6250 - val_loss: 3370.4241\n",
            "Epoch 81/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3690.9463 - val_loss: 3301.7390\n",
            "Epoch 82/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3490.7158 - val_loss: 3185.1614\n",
            "Epoch 83/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3649.4541 - val_loss: 3596.8347\n",
            "Epoch 84/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3766.2973 - val_loss: 3147.0938\n",
            "Epoch 85/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3561.2384 - val_loss: 3132.7468\n",
            "Epoch 86/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3582.3561 - val_loss: 3240.0244\n",
            "Epoch 87/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3621.1405 - val_loss: 3126.0017\n",
            "Epoch 88/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3339.5861 - val_loss: 3289.8579\n",
            "Epoch 89/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3799.4094 - val_loss: 3198.7632\n",
            "Epoch 90/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3746.8428 - val_loss: 3130.1252\n",
            "Epoch 91/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3803.6222 - val_loss: 3084.0938\n",
            "Epoch 92/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3941.6513 - val_loss: 3609.0332\n",
            "Epoch 93/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3804.6234 - val_loss: 3144.8848\n",
            "Epoch 94/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3850.6034 - val_loss: 3130.0093\n",
            "Epoch 95/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3689.6400 - val_loss: 3244.0203\n",
            "Epoch 96/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3662.8847 - val_loss: 3116.6226\n",
            "Epoch 97/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3554.2713 - val_loss: 3107.1099\n",
            "Epoch 98/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4014.7046 - val_loss: 3617.2156\n",
            "Epoch 99/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4098.8957 - val_loss: 3135.3928\n",
            "Epoch 100/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3957.9780 - val_loss: 3161.7551\n",
            "Epoch 101/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3766.6684 - val_loss: 3264.1477\n",
            "Epoch 102/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3412.2881 - val_loss: 3149.5969\n",
            "Epoch 103/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3645.4224 - val_loss: 3096.2625\n",
            "Epoch 104/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3797.7894 - val_loss: 3033.8025\n",
            "Epoch 105/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3626.6396 - val_loss: 3042.5813\n",
            "Epoch 106/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3526.5127 - val_loss: 3066.2107\n",
            "Epoch 107/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3827.5937 - val_loss: 3064.2849\n",
            "Epoch 108/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3726.3334 - val_loss: 3175.8157\n",
            "Epoch 109/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3858.7788 - val_loss: 3219.0171\n",
            "Epoch 110/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3377.7295 - val_loss: 3096.4807\n",
            "Epoch 111/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3601.1682 - val_loss: 3021.5186\n",
            "Epoch 112/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3663.1772 - val_loss: 3165.5918\n",
            "Epoch 113/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3686.3346 - val_loss: 3067.2087\n",
            "Epoch 114/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3712.3619 - val_loss: 3083.9683\n",
            "Epoch 115/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3381.6021 - val_loss: 3023.8606\n",
            "Epoch 116/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3350.0283 - val_loss: 3043.5691\n",
            "Epoch 117/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3878.6630 - val_loss: 3264.0242\n",
            "Epoch 118/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3604.1401 - val_loss: 3261.8020\n",
            "Epoch 119/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3708.7063 - val_loss: 2985.1724\n",
            "Epoch 120/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3452.7536 - val_loss: 3017.1594\n",
            "Epoch 121/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3724.4007 - val_loss: 3106.6777\n",
            "Epoch 122/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3579.6422 - val_loss: 3069.2446\n",
            "Epoch 123/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 4002.8142 - val_loss: 3034.0137\n",
            "Epoch 124/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3609.3865 - val_loss: 3001.6558\n",
            "Epoch 125/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3479.4868 - val_loss: 2990.8628\n",
            "Epoch 126/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3499.6602 - val_loss: 3215.0081\n",
            "Epoch 127/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3386.7003 - val_loss: 2991.2273\n",
            "Epoch 128/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3755.8915 - val_loss: 2972.3591\n",
            "Epoch 129/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3586.9854 - val_loss: 3262.8311\n",
            "Epoch 130/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3625.3036 - val_loss: 3052.7512\n",
            "Epoch 131/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3586.4759 - val_loss: 2960.0273\n",
            "Epoch 132/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3487.2904 - val_loss: 3012.9146\n",
            "Epoch 133/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3605.8181 - val_loss: 3393.1716\n",
            "Epoch 134/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3928.4311 - val_loss: 3102.2502\n",
            "Epoch 135/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3512.4317 - val_loss: 2964.1514\n",
            "Epoch 136/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3663.3682 - val_loss: 3657.6348\n",
            "Epoch 137/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3842.9084 - val_loss: 2995.5942\n",
            "Epoch 138/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3601.8528 - val_loss: 2962.4275\n",
            "Epoch 139/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3452.4419 - val_loss: 3085.4482\n",
            "Epoch 140/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3393.1696 - val_loss: 3165.2974\n",
            "Epoch 141/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3210.3647 - val_loss: 2944.2219\n",
            "Epoch 142/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3588.4824 - val_loss: 2994.7314\n",
            "Epoch 143/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3731.7327 - val_loss: 3173.9446\n",
            "Epoch 144/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3385.7709 - val_loss: 2929.5469\n",
            "Epoch 145/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3481.1383 - val_loss: 2932.1191\n",
            "Epoch 146/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3358.9695 - val_loss: 3033.1235\n",
            "Epoch 147/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3547.0386 - val_loss: 3325.4429\n",
            "Epoch 148/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3903.3174 - val_loss: 3058.1145\n",
            "Epoch 149/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3823.1641 - val_loss: 2937.5449\n",
            "Epoch 150/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3610.8366 - val_loss: 3156.0820\n",
            "Epoch 151/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3369.3750 - val_loss: 2964.7920\n",
            "Epoch 152/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3467.7668 - val_loss: 2970.1775\n",
            "Epoch 153/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3415.7740 - val_loss: 3242.0107\n",
            "Epoch 154/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3884.9826 - val_loss: 3025.2715\n",
            "Epoch 155/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3285.1712 - val_loss: 2960.7500\n",
            "Epoch 156/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3648.9682 - val_loss: 3085.0310\n",
            "Epoch 157/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3490.6282 - val_loss: 2955.5181\n",
            "Epoch 158/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3380.7381 - val_loss: 2952.9668\n",
            "Epoch 159/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3505.4611 - val_loss: 2951.8892\n",
            "Epoch 160/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3563.8322 - val_loss: 3034.3972\n",
            "Epoch 161/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3525.0161 - val_loss: 2939.7747\n",
            "Epoch 162/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3549.6967 - val_loss: 2985.5063\n",
            "Epoch 163/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3510.4931 - val_loss: 2938.9397\n",
            "Epoch 164/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3420.0898 - val_loss: 2949.6338\n",
            "Epoch 165/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3682.9496 - val_loss: 2927.1045\n",
            "Epoch 166/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3452.5244 - val_loss: 2953.0857\n",
            "Epoch 167/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3283.9110 - val_loss: 2994.8674\n",
            "Epoch 168/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3384.1379 - val_loss: 2933.0588\n",
            "Epoch 169/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3566.6485 - val_loss: 2922.6350\n",
            "Epoch 170/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3652.7638 - val_loss: 2914.0869\n",
            "Epoch 171/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3460.9818 - val_loss: 3020.6550\n",
            "Epoch 172/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3529.5334 - val_loss: 2969.4028\n",
            "Epoch 173/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3427.0810 - val_loss: 2946.2297\n",
            "Epoch 174/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3609.8578 - val_loss: 3179.5093\n",
            "Epoch 175/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3507.6952 - val_loss: 3002.2100\n",
            "Epoch 176/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3483.1768 - val_loss: 2926.6960\n",
            "Epoch 177/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3486.5019 - val_loss: 3262.4341\n",
            "Epoch 178/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3501.9141 - val_loss: 3077.6018\n",
            "Epoch 179/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3386.9998 - val_loss: 3062.1821\n",
            "Epoch 180/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3501.4610 - val_loss: 2928.2156\n",
            "Epoch 181/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3506.8906 - val_loss: 3075.1021\n",
            "Epoch 182/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3729.2671 - val_loss: 2926.3228\n",
            "Epoch 183/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3670.0337 - val_loss: 3096.7661\n",
            "Epoch 184/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3760.2202 - val_loss: 2971.7166\n",
            "Epoch 185/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3568.1881 - val_loss: 2896.4788\n",
            "Epoch 186/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3343.9320 - val_loss: 2987.8250\n",
            "Epoch 187/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3468.1812 - val_loss: 2953.4580\n",
            "Epoch 188/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3335.6598 - val_loss: 2986.3970\n",
            "Epoch 189/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3778.2250 - val_loss: 2955.3936\n",
            "Epoch 190/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3649.5796 - val_loss: 3020.0088\n",
            "Epoch 191/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3438.5260 - val_loss: 2945.9167\n",
            "Epoch 192/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3486.1019 - val_loss: 2884.9548\n",
            "Epoch 193/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3600.6773 - val_loss: 3177.2917\n",
            "Epoch 194/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3760.2402 - val_loss: 2955.9417\n",
            "Epoch 195/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3699.6424 - val_loss: 2947.7224\n",
            "Epoch 196/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3579.0773 - val_loss: 3081.6931\n",
            "Epoch 197/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3506.7138 - val_loss: 2959.5693\n",
            "Epoch 198/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3575.9592 - val_loss: 2925.6482\n",
            "Epoch 199/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3621.9144 - val_loss: 3077.6758\n",
            "Epoch 200/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3386.5817 - val_loss: 2906.5007\n",
            "Epoch 201/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3391.1508 - val_loss: 3055.2988\n",
            "Epoch 202/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3575.9913 - val_loss: 2934.5576\n",
            "Epoch 203/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3487.5785 - val_loss: 2939.0237\n",
            "Epoch 204/400\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3341.8023 - val_loss: 2899.0586\n",
            "Epoch 205/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3303.5301 - val_loss: 3114.1289\n",
            "Epoch 206/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3472.3173 - val_loss: 2895.2402\n",
            "Epoch 207/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3715.3945 - val_loss: 2898.4346\n",
            "Epoch 208/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3460.6912 - val_loss: 3256.7310\n",
            "Epoch 209/400\n",
            "8/8 [==============================] - 0s 5ms/step - loss: 3782.1523 - val_loss: 3046.3987\n",
            "Epoch 210/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3546.8026 - val_loss: 2913.1631\n",
            "Epoch 211/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3617.4489 - val_loss: 3057.9949\n",
            "Epoch 212/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3529.0256 - val_loss: 2972.5261\n",
            "Epoch 213/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3184.2373 - val_loss: 2985.8010\n",
            "Epoch 214/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3496.7904 - val_loss: 2994.0835\n",
            "Epoch 215/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3128.3118 - val_loss: 2903.4438\n",
            "Epoch 216/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3532.2587 - val_loss: 3179.2620\n",
            "Epoch 217/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3621.4657 - val_loss: 2893.3232\n",
            "Epoch 218/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3760.7412 - val_loss: 2888.7488\n",
            "Epoch 219/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3195.8609 - val_loss: 3341.8420\n",
            "Epoch 220/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3594.5979 - val_loss: 2884.8804\n",
            "Epoch 221/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3640.6293 - val_loss: 2933.1313\n",
            "Epoch 222/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3333.4547 - val_loss: 3055.8042\n",
            "Epoch 223/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3595.3839 - val_loss: 2973.8799\n",
            "Epoch 224/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3481.1263 - val_loss: 3215.7437\n",
            "Epoch 225/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3889.2848 - val_loss: 2977.4507\n",
            "Epoch 226/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3349.2154 - val_loss: 2858.6226\n",
            "Epoch 227/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3546.3752 - val_loss: 3212.0081\n",
            "Epoch 228/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3590.0406 - val_loss: 2875.7695\n",
            "Epoch 229/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3346.4399 - val_loss: 2911.2727\n",
            "Epoch 230/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3553.2233 - val_loss: 2977.1975\n",
            "Epoch 231/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3489.3165 - val_loss: 2947.9995\n",
            "Epoch 232/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3471.2492 - val_loss: 3075.3384\n",
            "Epoch 233/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3506.6842 - val_loss: 3184.8940\n",
            "Epoch 234/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3398.7656 - val_loss: 2891.9709\n",
            "Epoch 235/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3382.3676 - val_loss: 2915.0344\n",
            "Epoch 236/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3546.9779 - val_loss: 2906.2493\n",
            "Epoch 237/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3714.1819 - val_loss: 3061.3323\n",
            "Epoch 238/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3502.2493 - val_loss: 2891.1431\n",
            "Epoch 239/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3401.0268 - val_loss: 2957.6011\n",
            "Epoch 240/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3338.1449 - val_loss: 3141.1792\n",
            "Epoch 241/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3474.5738 - val_loss: 2892.8025\n",
            "Epoch 242/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3562.4757 - val_loss: 2938.4514\n",
            "Epoch 243/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3570.4763 - val_loss: 3184.2424\n",
            "Epoch 244/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3439.1390 - val_loss: 2905.4290\n",
            "Epoch 245/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3359.4011 - val_loss: 2891.6824\n",
            "Epoch 246/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3266.3633 - val_loss: 3117.5239\n",
            "Epoch 247/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3585.0136 - val_loss: 2864.4316\n",
            "Epoch 248/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3414.0416 - val_loss: 2881.8472\n",
            "Epoch 249/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3233.4319 - val_loss: 3098.7112\n",
            "Epoch 250/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3252.9057 - val_loss: 2896.4890\n",
            "Epoch 251/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3529.4272 - val_loss: 2896.8960\n",
            "Epoch 252/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3670.9289 - val_loss: 3016.4067\n",
            "Epoch 253/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3492.8848 - val_loss: 3106.9250\n",
            "Epoch 254/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3246.5167 - val_loss: 2902.4512\n",
            "Epoch 255/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3450.6963 - val_loss: 2906.8467\n",
            "Epoch 256/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3443.2552 - val_loss: 2893.3445\n",
            "Epoch 257/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3307.9425 - val_loss: 2898.6101\n",
            "Epoch 258/400\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 3320.2797 - val_loss: 2903.8323\n",
            "Epoch 259/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3438.3201 - val_loss: 2885.7971\n",
            "Epoch 260/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3466.4361 - val_loss: 3095.8818\n",
            "Epoch 261/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3701.0436 - val_loss: 2881.9751\n",
            "Epoch 262/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3521.7208 - val_loss: 2899.7026\n",
            "Epoch 263/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 4010.7519 - val_loss: 3158.2517\n",
            "Epoch 264/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3656.1429 - val_loss: 2974.3350\n",
            "Epoch 265/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3608.9720 - val_loss: 2863.0886\n",
            "Epoch 266/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3188.5885 - val_loss: 2873.7539\n",
            "Epoch 267/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3611.9499 - val_loss: 2873.0784\n",
            "Epoch 268/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3422.4589 - val_loss: 2909.0762\n",
            "Epoch 269/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3352.6284 - val_loss: 2877.1357\n",
            "Epoch 270/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3268.7978 - val_loss: 2861.7900\n",
            "Epoch 271/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3411.7655 - val_loss: 2901.3545\n",
            "Epoch 272/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3229.6772 - val_loss: 2896.4233\n",
            "Epoch 273/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3564.3659 - val_loss: 2859.6594\n",
            "Epoch 274/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3585.3438 - val_loss: 3100.1946\n",
            "Epoch 275/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3247.6921 - val_loss: 2890.2168\n",
            "Epoch 276/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3468.8118 - val_loss: 3002.7239\n",
            "Epoch 277/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3349.7085 - val_loss: 2857.8228\n",
            "Epoch 278/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3281.8211 - val_loss: 2842.9536\n",
            "Epoch 279/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3274.8301 - val_loss: 2942.7820\n",
            "Epoch 280/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3548.1681 - val_loss: 2989.5259\n",
            "Epoch 281/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3279.9602 - val_loss: 2874.0020\n",
            "Epoch 282/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3322.8656 - val_loss: 2996.2212\n",
            "Epoch 283/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3393.9329 - val_loss: 2961.9902\n",
            "Epoch 284/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3134.1564 - val_loss: 2815.9597\n",
            "Epoch 285/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3627.6224 - val_loss: 2950.9946\n",
            "Epoch 286/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3735.7930 - val_loss: 3125.8542\n",
            "Epoch 287/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3383.4259 - val_loss: 2846.9512\n",
            "Epoch 288/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3324.6328 - val_loss: 2830.5579\n",
            "Epoch 289/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3308.4481 - val_loss: 3281.0474\n",
            "Epoch 290/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3457.8235 - val_loss: 2847.4329\n",
            "Epoch 291/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3494.0854 - val_loss: 2836.1921\n",
            "Epoch 292/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3539.4089 - val_loss: 2929.1267\n",
            "Epoch 293/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3335.9496 - val_loss: 3196.4534\n",
            "Epoch 294/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3300.3761 - val_loss: 2964.8333\n",
            "Epoch 295/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3630.7764 - val_loss: 3034.8640\n",
            "Epoch 296/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3168.0400 - val_loss: 2866.0798\n",
            "Epoch 297/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3254.1156 - val_loss: 2868.2759\n",
            "Epoch 298/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3449.0063 - val_loss: 2922.5005\n",
            "Epoch 299/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3318.8402 - val_loss: 2846.9668\n",
            "Epoch 300/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3601.5355 - val_loss: 2855.4531\n",
            "Epoch 301/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3293.1968 - val_loss: 2956.4868\n",
            "Epoch 302/400\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3110.0217 - val_loss: 2812.2285\n",
            "Epoch 303/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3431.6225 - val_loss: 2835.1272\n",
            "Epoch 304/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3210.0923 - val_loss: 3149.4709\n",
            "Epoch 305/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3188.5274 - val_loss: 2936.6243\n",
            "Epoch 306/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3568.3928 - val_loss: 2829.7012\n",
            "Epoch 307/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3541.4173 - val_loss: 2815.0034\n",
            "Epoch 308/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3471.6993 - val_loss: 2824.4944\n",
            "Epoch 309/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3350.1419 - val_loss: 3011.4221\n",
            "Epoch 310/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3354.0294 - val_loss: 2919.1943\n",
            "Epoch 311/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3409.4967 - val_loss: 3063.7986\n",
            "Epoch 312/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3443.3615 - val_loss: 2890.2686\n",
            "Epoch 313/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3426.6170 - val_loss: 2813.3298\n",
            "Epoch 314/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3236.9689 - val_loss: 2827.5447\n",
            "Epoch 315/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3480.4863 - val_loss: 2929.9219\n",
            "Epoch 316/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3311.2519 - val_loss: 3055.4341\n",
            "Epoch 317/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3177.0805 - val_loss: 2817.8274\n",
            "Epoch 318/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3394.8793 - val_loss: 2841.5498\n",
            "Epoch 319/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3156.2377 - val_loss: 2813.8018\n",
            "Epoch 320/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3273.6340 - val_loss: 2905.2900\n",
            "Epoch 321/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3650.3636 - val_loss: 2824.2722\n",
            "Epoch 322/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3263.2814 - val_loss: 2962.6008\n",
            "Epoch 323/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3476.1702 - val_loss: 2835.1301\n",
            "Epoch 324/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3345.0604 - val_loss: 2914.6455\n",
            "Epoch 325/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3496.1123 - val_loss: 2813.9758\n",
            "Epoch 326/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3452.5500 - val_loss: 2817.2415\n",
            "Epoch 327/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3321.6576 - val_loss: 2799.8936\n",
            "Epoch 328/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3361.2329 - val_loss: 2825.4612\n",
            "Epoch 329/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3576.9536 - val_loss: 2910.5676\n",
            "Epoch 330/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3545.5975 - val_loss: 3078.6938\n",
            "Epoch 331/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3507.0838 - val_loss: 2869.5100\n",
            "Epoch 332/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3526.7272 - val_loss: 2923.0576\n",
            "Epoch 333/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3510.3940 - val_loss: 3179.2251\n",
            "Epoch 334/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3289.1900 - val_loss: 2802.0190\n",
            "Epoch 335/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3170.0170 - val_loss: 2911.1687\n",
            "Epoch 336/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3556.1954 - val_loss: 2805.3704\n",
            "Epoch 337/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3361.9040 - val_loss: 2860.7546\n",
            "Epoch 338/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3461.1685 - val_loss: 2783.0593\n",
            "Epoch 339/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3502.1586 - val_loss: 2792.2795\n",
            "Epoch 340/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3304.6977 - val_loss: 2793.4136\n",
            "Epoch 341/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3164.8883 - val_loss: 2810.8071\n",
            "Epoch 342/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3238.2848 - val_loss: 2792.6968\n",
            "Epoch 343/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3298.3331 - val_loss: 2814.0427\n",
            "Epoch 344/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3339.1333 - val_loss: 2845.0908\n",
            "Epoch 345/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3203.3346 - val_loss: 2798.5400\n",
            "Epoch 346/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3627.5430 - val_loss: 2815.4368\n",
            "Epoch 347/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3439.3011 - val_loss: 2892.4014\n",
            "Epoch 348/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3246.9837 - val_loss: 2975.7239\n",
            "Epoch 349/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3381.9443 - val_loss: 3052.1743\n",
            "Epoch 350/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3366.5141 - val_loss: 2838.8943\n",
            "Epoch 351/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3379.7818 - val_loss: 3099.1882\n",
            "Epoch 352/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3466.6121 - val_loss: 2773.1057\n",
            "Epoch 353/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3644.9012 - val_loss: 2983.5920\n",
            "Epoch 354/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3614.9247 - val_loss: 2855.4294\n",
            "Epoch 355/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3181.5830 - val_loss: 2764.1021\n",
            "Epoch 356/400\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3046.3255 - val_loss: 2772.3171\n",
            "Epoch 357/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3355.5602 - val_loss: 2760.0574\n",
            "Epoch 358/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3356.8958 - val_loss: 2749.2605\n",
            "Epoch 359/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3445.7367 - val_loss: 2730.5122\n",
            "Epoch 360/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3412.7326 - val_loss: 2959.6892\n",
            "Epoch 361/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3397.8860 - val_loss: 2843.2441\n",
            "Epoch 362/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3186.2724 - val_loss: 2760.9275\n",
            "Epoch 363/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3581.9038 - val_loss: 2765.5432\n",
            "Epoch 364/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3185.9072 - val_loss: 2782.5852\n",
            "Epoch 365/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3504.7441 - val_loss: 2829.2268\n",
            "Epoch 366/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3350.0400 - val_loss: 2827.1306\n",
            "Epoch 367/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3136.4425 - val_loss: 2737.7671\n",
            "Epoch 368/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3492.1524 - val_loss: 3059.6926\n",
            "Epoch 369/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3440.2326 - val_loss: 2863.9238\n",
            "Epoch 370/400\n",
            "8/8 [==============================] - 0s 10ms/step - loss: 3546.7042 - val_loss: 2733.1829\n",
            "Epoch 371/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3374.3161 - val_loss: 2861.5779\n",
            "Epoch 372/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3375.3668 - val_loss: 2826.6262\n",
            "Epoch 373/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3232.2898 - val_loss: 2780.8633\n",
            "Epoch 374/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 2940.2996 - val_loss: 2744.1123\n",
            "Epoch 375/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3220.6078 - val_loss: 2851.8225\n",
            "Epoch 376/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3663.8777 - val_loss: 2835.6313\n",
            "Epoch 377/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3402.6247 - val_loss: 2723.1619\n",
            "Epoch 378/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3279.9010 - val_loss: 2812.3242\n",
            "Epoch 379/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3218.5558 - val_loss: 2785.7583\n",
            "Epoch 380/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3405.7141 - val_loss: 2775.4536\n",
            "Epoch 381/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3379.5309 - val_loss: 2735.9641\n",
            "Epoch 382/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3532.3325 - val_loss: 2896.5254\n",
            "Epoch 383/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3250.0230 - val_loss: 3015.3350\n",
            "Epoch 384/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3310.9858 - val_loss: 2729.5227\n",
            "Epoch 385/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3238.3296 - val_loss: 2715.1619\n",
            "Epoch 386/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3038.9079 - val_loss: 2784.5349\n",
            "Epoch 387/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3471.3586 - val_loss: 2709.6794\n",
            "Epoch 388/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3678.2314 - val_loss: 2994.1414\n",
            "Epoch 389/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3158.2784 - val_loss: 2768.2651\n",
            "Epoch 390/400\n",
            "8/8 [==============================] - 0s 11ms/step - loss: 3479.3114 - val_loss: 2741.4978\n",
            "Epoch 391/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3220.0097 - val_loss: 2766.0471\n",
            "Epoch 392/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3223.7930 - val_loss: 2754.0654\n",
            "Epoch 393/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3205.6547 - val_loss: 2768.9358\n",
            "Epoch 394/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3388.4675 - val_loss: 2740.8875\n",
            "Epoch 395/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3217.1742 - val_loss: 2836.0271\n",
            "Epoch 396/400\n",
            "8/8 [==============================] - 0s 9ms/step - loss: 3041.7133 - val_loss: 2702.0039\n",
            "Epoch 397/400\n",
            "8/8 [==============================] - 0s 6ms/step - loss: 3414.0946 - val_loss: 2706.3489\n",
            "Epoch 398/400\n",
            "8/8 [==============================] - 0s 7ms/step - loss: 3060.1778 - val_loss: 2785.0515\n",
            "Epoch 399/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3247.4954 - val_loss: 3061.9097\n",
            "Epoch 400/400\n",
            "8/8 [==============================] - 0s 8ms/step - loss: 3511.8552 - val_loss: 2723.9109\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f18264491d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZmzLuRAvRL5"
      },
      "source": [
        "y_pred = model.predict(X_val)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "id": "m7AUrIGzvZkx",
        "outputId": "3ab3610b-e602-40e9-acfe-84541753031d"
      },
      "source": [
        "from sklearn import metrics\r\n",
        "import numpy as np\r\n",
        "\r\n",
        "print('MAE:', metrics.mean_absolute_error(y_val, y_pred))  \r\n",
        "print('MSE:', metrics.mean_squared_error(y_val, y_pred))  \r\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(y_val, y_pred)))\r\n",
        "print('VarScore:',metrics.explained_variance_score(y_val,y_pred))\r\n",
        "# Visualizing Our predictions\r\n",
        "fig = plt.figure(figsize=(10,5))\r\n",
        "plt.scatter(y_val,y_pred)\r\n",
        "# Perfect predictions\r\n",
        "plt.plot(y_val,y_val,'r')"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 36.63723612236254\n",
            "MSE: 2723.9109367076812\n",
            "RMSE: 52.19110016763089\n",
            "VarScore: 0.6361123658965039\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f182a3e5198>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x360 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "vVe8rWdvvdjh",
        "outputId": "cdfb76a1-068c-4dae-92f1-acc51d892544"
      },
      "source": [
        "y = np.array(y_val)\r\n",
        "y_p = np.array(y_pred).flatten()\r\n",
        "df = pd.DataFrame({\"Test Data\": y, \"Predicted Data\": y_p})\r\n",
        "df.head(100)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Test Data</th>\n",
              "      <th>Predicted Data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33.791667</td>\n",
              "      <td>54.715805</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>30.333333</td>\n",
              "      <td>57.571880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>97.291667</td>\n",
              "      <td>70.091835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>26.583333</td>\n",
              "      <td>32.927692</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>284.795833</td>\n",
              "      <td>219.760986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>154.037500</td>\n",
              "      <td>189.016785</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>82.833333</td>\n",
              "      <td>60.685047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>93.500000</td>\n",
              "      <td>81.172127</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>120.208333</td>\n",
              "      <td>189.856125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>77.708333</td>\n",
              "      <td>86.259079</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Test Data  Predicted Data\n",
              "0    33.791667       54.715805\n",
              "1    30.333333       57.571880\n",
              "2    97.291667       70.091835\n",
              "3    26.583333       32.927692\n",
              "4   284.795833      219.760986\n",
              "..         ...             ...\n",
              "95  154.037500      189.016785\n",
              "96   82.833333       60.685047\n",
              "97   93.500000       81.172127\n",
              "98  120.208333      189.856125\n",
              "99   77.708333       86.259079\n",
              "\n",
              "[100 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    }
  ]
}