{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "House_Renting_PreDiction_Neural_Network.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBdJNIU5l7rk"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNohUK3pmWf_"
      },
      "source": [
        "from sklearn.datasets import load_boston\r\n",
        "boston = load_boston()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jsON48bmbLm",
        "outputId": "2356ee9d-531e-42a2-8eeb-e21892c56ad7"
      },
      "source": [
        "dataFrame_X = pd.DataFrame(boston.data, columns= boston.feature_names)\r\n",
        "print(dataFrame_X.head(5))\r\n",
        "dataFrame_Y = pd.DataFrame(boston.target)\r\n",
        "print(dataFrame_Y.head(5))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      CRIM    ZN  INDUS  CHAS    NOX  ...  RAD    TAX  PTRATIO       B  LSTAT\n",
            "0  0.00632  18.0   2.31   0.0  0.538  ...  1.0  296.0     15.3  396.90   4.98\n",
            "1  0.02731   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  396.90   9.14\n",
            "2  0.02729   0.0   7.07   0.0  0.469  ...  2.0  242.0     17.8  392.83   4.03\n",
            "3  0.03237   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  394.63   2.94\n",
            "4  0.06905   0.0   2.18   0.0  0.458  ...  3.0  222.0     18.7  396.90   5.33\n",
            "\n",
            "[5 rows x 13 columns]\n",
            "      0\n",
            "0  24.0\n",
            "1  21.6\n",
            "2  34.7\n",
            "3  33.4\n",
            "4  36.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 432
        },
        "id": "e6wPyx1FmfVP",
        "outputId": "df41afba-16fd-4ae3-a8d7-522fb1a441d9"
      },
      "source": [
        "dataFrame_X.corr()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>CRIM</th>\n",
              "      <th>ZN</th>\n",
              "      <th>INDUS</th>\n",
              "      <th>CHAS</th>\n",
              "      <th>NOX</th>\n",
              "      <th>RM</th>\n",
              "      <th>AGE</th>\n",
              "      <th>DIS</th>\n",
              "      <th>RAD</th>\n",
              "      <th>TAX</th>\n",
              "      <th>PTRATIO</th>\n",
              "      <th>B</th>\n",
              "      <th>LSTAT</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>CRIM</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.200469</td>\n",
              "      <td>0.406583</td>\n",
              "      <td>-0.055892</td>\n",
              "      <td>0.420972</td>\n",
              "      <td>-0.219247</td>\n",
              "      <td>0.352734</td>\n",
              "      <td>-0.379670</td>\n",
              "      <td>0.625505</td>\n",
              "      <td>0.582764</td>\n",
              "      <td>0.289946</td>\n",
              "      <td>-0.385064</td>\n",
              "      <td>0.455621</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ZN</th>\n",
              "      <td>-0.200469</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.533828</td>\n",
              "      <td>-0.042697</td>\n",
              "      <td>-0.516604</td>\n",
              "      <td>0.311991</td>\n",
              "      <td>-0.569537</td>\n",
              "      <td>0.664408</td>\n",
              "      <td>-0.311948</td>\n",
              "      <td>-0.314563</td>\n",
              "      <td>-0.391679</td>\n",
              "      <td>0.175520</td>\n",
              "      <td>-0.412995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INDUS</th>\n",
              "      <td>0.406583</td>\n",
              "      <td>-0.533828</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.062938</td>\n",
              "      <td>0.763651</td>\n",
              "      <td>-0.391676</td>\n",
              "      <td>0.644779</td>\n",
              "      <td>-0.708027</td>\n",
              "      <td>0.595129</td>\n",
              "      <td>0.720760</td>\n",
              "      <td>0.383248</td>\n",
              "      <td>-0.356977</td>\n",
              "      <td>0.603800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CHAS</th>\n",
              "      <td>-0.055892</td>\n",
              "      <td>-0.042697</td>\n",
              "      <td>0.062938</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.091203</td>\n",
              "      <td>0.091251</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>-0.099176</td>\n",
              "      <td>-0.007368</td>\n",
              "      <td>-0.035587</td>\n",
              "      <td>-0.121515</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>-0.053929</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>NOX</th>\n",
              "      <td>0.420972</td>\n",
              "      <td>-0.516604</td>\n",
              "      <td>0.763651</td>\n",
              "      <td>0.091203</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.302188</td>\n",
              "      <td>0.731470</td>\n",
              "      <td>-0.769230</td>\n",
              "      <td>0.611441</td>\n",
              "      <td>0.668023</td>\n",
              "      <td>0.188933</td>\n",
              "      <td>-0.380051</td>\n",
              "      <td>0.590879</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RM</th>\n",
              "      <td>-0.219247</td>\n",
              "      <td>0.311991</td>\n",
              "      <td>-0.391676</td>\n",
              "      <td>0.091251</td>\n",
              "      <td>-0.302188</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.240265</td>\n",
              "      <td>0.205246</td>\n",
              "      <td>-0.209847</td>\n",
              "      <td>-0.292048</td>\n",
              "      <td>-0.355501</td>\n",
              "      <td>0.128069</td>\n",
              "      <td>-0.613808</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>AGE</th>\n",
              "      <td>0.352734</td>\n",
              "      <td>-0.569537</td>\n",
              "      <td>0.644779</td>\n",
              "      <td>0.086518</td>\n",
              "      <td>0.731470</td>\n",
              "      <td>-0.240265</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.747881</td>\n",
              "      <td>0.456022</td>\n",
              "      <td>0.506456</td>\n",
              "      <td>0.261515</td>\n",
              "      <td>-0.273534</td>\n",
              "      <td>0.602339</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DIS</th>\n",
              "      <td>-0.379670</td>\n",
              "      <td>0.664408</td>\n",
              "      <td>-0.708027</td>\n",
              "      <td>-0.099176</td>\n",
              "      <td>-0.769230</td>\n",
              "      <td>0.205246</td>\n",
              "      <td>-0.747881</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.494588</td>\n",
              "      <td>-0.534432</td>\n",
              "      <td>-0.232471</td>\n",
              "      <td>0.291512</td>\n",
              "      <td>-0.496996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RAD</th>\n",
              "      <td>0.625505</td>\n",
              "      <td>-0.311948</td>\n",
              "      <td>0.595129</td>\n",
              "      <td>-0.007368</td>\n",
              "      <td>0.611441</td>\n",
              "      <td>-0.209847</td>\n",
              "      <td>0.456022</td>\n",
              "      <td>-0.494588</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.910228</td>\n",
              "      <td>0.464741</td>\n",
              "      <td>-0.444413</td>\n",
              "      <td>0.488676</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TAX</th>\n",
              "      <td>0.582764</td>\n",
              "      <td>-0.314563</td>\n",
              "      <td>0.720760</td>\n",
              "      <td>-0.035587</td>\n",
              "      <td>0.668023</td>\n",
              "      <td>-0.292048</td>\n",
              "      <td>0.506456</td>\n",
              "      <td>-0.534432</td>\n",
              "      <td>0.910228</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.460853</td>\n",
              "      <td>-0.441808</td>\n",
              "      <td>0.543993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>PTRATIO</th>\n",
              "      <td>0.289946</td>\n",
              "      <td>-0.391679</td>\n",
              "      <td>0.383248</td>\n",
              "      <td>-0.121515</td>\n",
              "      <td>0.188933</td>\n",
              "      <td>-0.355501</td>\n",
              "      <td>0.261515</td>\n",
              "      <td>-0.232471</td>\n",
              "      <td>0.464741</td>\n",
              "      <td>0.460853</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.177383</td>\n",
              "      <td>0.374044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>B</th>\n",
              "      <td>-0.385064</td>\n",
              "      <td>0.175520</td>\n",
              "      <td>-0.356977</td>\n",
              "      <td>0.048788</td>\n",
              "      <td>-0.380051</td>\n",
              "      <td>0.128069</td>\n",
              "      <td>-0.273534</td>\n",
              "      <td>0.291512</td>\n",
              "      <td>-0.444413</td>\n",
              "      <td>-0.441808</td>\n",
              "      <td>-0.177383</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.366087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LSTAT</th>\n",
              "      <td>0.455621</td>\n",
              "      <td>-0.412995</td>\n",
              "      <td>0.603800</td>\n",
              "      <td>-0.053929</td>\n",
              "      <td>0.590879</td>\n",
              "      <td>-0.613808</td>\n",
              "      <td>0.602339</td>\n",
              "      <td>-0.496996</td>\n",
              "      <td>0.488676</td>\n",
              "      <td>0.543993</td>\n",
              "      <td>0.374044</td>\n",
              "      <td>-0.366087</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             CRIM        ZN     INDUS  ...   PTRATIO         B     LSTAT\n",
              "CRIM     1.000000 -0.200469  0.406583  ...  0.289946 -0.385064  0.455621\n",
              "ZN      -0.200469  1.000000 -0.533828  ... -0.391679  0.175520 -0.412995\n",
              "INDUS    0.406583 -0.533828  1.000000  ...  0.383248 -0.356977  0.603800\n",
              "CHAS    -0.055892 -0.042697  0.062938  ... -0.121515  0.048788 -0.053929\n",
              "NOX      0.420972 -0.516604  0.763651  ...  0.188933 -0.380051  0.590879\n",
              "RM      -0.219247  0.311991 -0.391676  ... -0.355501  0.128069 -0.613808\n",
              "AGE      0.352734 -0.569537  0.644779  ...  0.261515 -0.273534  0.602339\n",
              "DIS     -0.379670  0.664408 -0.708027  ... -0.232471  0.291512 -0.496996\n",
              "RAD      0.625505 -0.311948  0.595129  ...  0.464741 -0.444413  0.488676\n",
              "TAX      0.582764 -0.314563  0.720760  ...  0.460853 -0.441808  0.543993\n",
              "PTRATIO  0.289946 -0.391679  0.383248  ...  1.000000 -0.177383  0.374044\n",
              "B       -0.385064  0.175520 -0.356977  ... -0.177383  1.000000 -0.366087\n",
              "LSTAT    0.455621 -0.412995  0.603800  ...  0.374044 -0.366087  1.000000\n",
              "\n",
              "[13 rows x 13 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "af1q23jImk7W"
      },
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(dataFrame_X,dataFrame_Y,test_size = 0.33,random_state=42)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "302x1peImn1u"
      },
      "source": [
        "import keras\r\n",
        "from keras.models import Sequential\r\n",
        "from keras.layers import Dense\r\n",
        "from keras.layers import LeakyReLU,PReLU,ELU\r\n",
        "from keras.layers import Dropout"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWz-8n8dmsnm",
        "outputId": "15203758-de9f-42d5-ea06-560dae9cd867"
      },
      "source": [
        "nuralNetworkModel = Sequential()\r\n",
        "\r\n",
        "# The Input Layer :\r\n",
        "nuralNetworkModel.add(Dense(128, kernel_initializer='normal',input_dim = X_train.shape[1], activation='relu'))\r\n",
        "\r\n",
        "# The Hidden Layers :\r\n",
        "nuralNetworkModel.add(Dense(256, kernel_initializer='normal',activation='relu'))\r\n",
        "nuralNetworkModel.add(Dense(256, kernel_initializer='normal',activation='relu'))\r\n",
        "nuralNetworkModel.add(Dense(256, kernel_initializer='normal',activation='relu'))\r\n",
        "nuralNetworkModel.add(Dense(256, kernel_initializer='normal',activation='relu'))\r\n",
        "nuralNetworkModel.add(Dense(256, kernel_initializer='normal',activation='relu'))\r\n",
        "\r\n",
        "# The Output Layer :\r\n",
        "nuralNetworkModel.add(Dense(1, kernel_initializer='normal',activation='linear'))\r\n",
        "\r\n",
        "# Compile the network :\r\n",
        "nuralNetworkModel.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\r\n",
        "nuralNetworkModel.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               1792      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               33024     \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 256)               65792     \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 298,241\n",
            "Trainable params: 298,241\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnWgS5MBm1FQ",
        "outputId": "9bb834e2-e5b1-4ee5-e57b-fbd8135745eb"
      },
      "source": [
        "nuralNetworkModel.fit(X_train, Y_train,validation_split=0.33, batch_size = 10, epochs = 100)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "23/23 [==============================] - 1s 24ms/step - loss: 14.1355 - mean_absolute_error: 14.1355 - val_loss: 6.1095 - val_mean_absolute_error: 6.1095\n",
            "Epoch 2/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8868 - mean_absolute_error: 5.8868 - val_loss: 5.6849 - val_mean_absolute_error: 5.6849\n",
            "Epoch 3/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 6.7674 - mean_absolute_error: 6.7674 - val_loss: 5.0123 - val_mean_absolute_error: 5.0123\n",
            "Epoch 4/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.3387 - mean_absolute_error: 6.3387 - val_loss: 7.0886 - val_mean_absolute_error: 7.0886\n",
            "Epoch 5/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 6.3895 - mean_absolute_error: 6.3895 - val_loss: 5.6056 - val_mean_absolute_error: 5.6056\n",
            "Epoch 6/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.4938 - mean_absolute_error: 5.4938 - val_loss: 5.2342 - val_mean_absolute_error: 5.2342\n",
            "Epoch 7/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.8203 - mean_absolute_error: 5.8203 - val_loss: 5.9184 - val_mean_absolute_error: 5.9184\n",
            "Epoch 8/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 6.3506 - mean_absolute_error: 6.3506 - val_loss: 6.0455 - val_mean_absolute_error: 6.0455\n",
            "Epoch 9/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 6.1040 - mean_absolute_error: 6.1040 - val_loss: 5.6515 - val_mean_absolute_error: 5.6515\n",
            "Epoch 10/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.4503 - mean_absolute_error: 5.4503 - val_loss: 5.0616 - val_mean_absolute_error: 5.0616\n",
            "Epoch 11/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.4049 - mean_absolute_error: 5.4049 - val_loss: 5.2247 - val_mean_absolute_error: 5.2247\n",
            "Epoch 12/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.4075 - mean_absolute_error: 5.4075 - val_loss: 4.9890 - val_mean_absolute_error: 4.9890\n",
            "Epoch 13/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.1973 - mean_absolute_error: 5.1973 - val_loss: 5.0590 - val_mean_absolute_error: 5.0590\n",
            "Epoch 14/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.9844 - mean_absolute_error: 4.9844 - val_loss: 4.8045 - val_mean_absolute_error: 4.8045\n",
            "Epoch 15/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.0190 - mean_absolute_error: 5.0190 - val_loss: 4.8056 - val_mean_absolute_error: 4.8056\n",
            "Epoch 16/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.7452 - mean_absolute_error: 4.7452 - val_loss: 4.7523 - val_mean_absolute_error: 4.7523\n",
            "Epoch 17/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.3629 - mean_absolute_error: 4.3629 - val_loss: 4.7964 - val_mean_absolute_error: 4.7964\n",
            "Epoch 18/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7986 - mean_absolute_error: 4.7986 - val_loss: 4.5720 - val_mean_absolute_error: 4.5720\n",
            "Epoch 19/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.0197 - mean_absolute_error: 5.0197 - val_loss: 4.6129 - val_mean_absolute_error: 4.6129\n",
            "Epoch 20/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.0686 - mean_absolute_error: 5.0686 - val_loss: 5.4139 - val_mean_absolute_error: 5.4139\n",
            "Epoch 21/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 5.4211 - mean_absolute_error: 5.4211 - val_loss: 5.7273 - val_mean_absolute_error: 5.7273\n",
            "Epoch 22/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.8634 - mean_absolute_error: 4.8634 - val_loss: 4.5006 - val_mean_absolute_error: 4.5006\n",
            "Epoch 23/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.9834 - mean_absolute_error: 4.9834 - val_loss: 4.7734 - val_mean_absolute_error: 4.7734\n",
            "Epoch 24/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.0480 - mean_absolute_error: 5.0480 - val_loss: 4.8516 - val_mean_absolute_error: 4.8516\n",
            "Epoch 25/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.7791 - mean_absolute_error: 4.7791 - val_loss: 4.4659 - val_mean_absolute_error: 4.4659\n",
            "Epoch 26/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.7306 - mean_absolute_error: 4.7306 - val_loss: 4.2764 - val_mean_absolute_error: 4.2764\n",
            "Epoch 27/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.5210 - mean_absolute_error: 4.5210 - val_loss: 4.3889 - val_mean_absolute_error: 4.3889\n",
            "Epoch 28/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.4146 - mean_absolute_error: 4.4146 - val_loss: 4.2073 - val_mean_absolute_error: 4.2073\n",
            "Epoch 29/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.1786 - mean_absolute_error: 4.1786 - val_loss: 4.6207 - val_mean_absolute_error: 4.6207\n",
            "Epoch 30/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.0495 - mean_absolute_error: 4.0495 - val_loss: 4.1883 - val_mean_absolute_error: 4.1883\n",
            "Epoch 31/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.5839 - mean_absolute_error: 4.5839 - val_loss: 4.3975 - val_mean_absolute_error: 4.3975\n",
            "Epoch 32/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.9655 - mean_absolute_error: 3.9655 - val_loss: 5.0101 - val_mean_absolute_error: 5.0101\n",
            "Epoch 33/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.8660 - mean_absolute_error: 4.8660 - val_loss: 4.1750 - val_mean_absolute_error: 4.1750\n",
            "Epoch 34/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.0636 - mean_absolute_error: 4.0636 - val_loss: 4.3487 - val_mean_absolute_error: 4.3487\n",
            "Epoch 35/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.9550 - mean_absolute_error: 4.9550 - val_loss: 5.1364 - val_mean_absolute_error: 5.1364\n",
            "Epoch 36/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.0425 - mean_absolute_error: 4.0425 - val_loss: 3.9198 - val_mean_absolute_error: 3.9198\n",
            "Epoch 37/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.6175 - mean_absolute_error: 3.6175 - val_loss: 4.2344 - val_mean_absolute_error: 4.2344\n",
            "Epoch 38/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.5576 - mean_absolute_error: 4.5576 - val_loss: 5.0770 - val_mean_absolute_error: 5.0770\n",
            "Epoch 39/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.6301 - mean_absolute_error: 4.6301 - val_loss: 3.8921 - val_mean_absolute_error: 3.8921\n",
            "Epoch 40/100\n",
            "23/23 [==============================] - 0s 7ms/step - loss: 3.8793 - mean_absolute_error: 3.8793 - val_loss: 4.1108 - val_mean_absolute_error: 4.1108\n",
            "Epoch 41/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.3218 - mean_absolute_error: 4.3218 - val_loss: 7.0675 - val_mean_absolute_error: 7.0675\n",
            "Epoch 42/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 5.2514 - mean_absolute_error: 5.2514 - val_loss: 5.7780 - val_mean_absolute_error: 5.7780\n",
            "Epoch 43/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2452 - mean_absolute_error: 4.2452 - val_loss: 4.0131 - val_mean_absolute_error: 4.0131\n",
            "Epoch 44/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5809 - mean_absolute_error: 3.5809 - val_loss: 3.9488 - val_mean_absolute_error: 3.9488\n",
            "Epoch 45/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4694 - mean_absolute_error: 3.4694 - val_loss: 3.5787 - val_mean_absolute_error: 3.5787\n",
            "Epoch 46/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.7252 - mean_absolute_error: 3.7252 - val_loss: 3.7935 - val_mean_absolute_error: 3.7935\n",
            "Epoch 47/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.6076 - mean_absolute_error: 3.6076 - val_loss: 3.8781 - val_mean_absolute_error: 3.8781\n",
            "Epoch 48/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5195 - mean_absolute_error: 3.5195 - val_loss: 4.3607 - val_mean_absolute_error: 4.3607\n",
            "Epoch 49/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5758 - mean_absolute_error: 3.5758 - val_loss: 3.6122 - val_mean_absolute_error: 3.6122\n",
            "Epoch 50/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4947 - mean_absolute_error: 3.4947 - val_loss: 4.3666 - val_mean_absolute_error: 4.3666\n",
            "Epoch 51/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4927 - mean_absolute_error: 3.4927 - val_loss: 4.3130 - val_mean_absolute_error: 4.3130\n",
            "Epoch 52/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5144 - mean_absolute_error: 3.5144 - val_loss: 3.7231 - val_mean_absolute_error: 3.7231\n",
            "Epoch 53/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.7463 - mean_absolute_error: 3.7463 - val_loss: 3.7140 - val_mean_absolute_error: 3.7140\n",
            "Epoch 54/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.5697 - mean_absolute_error: 3.5697 - val_loss: 3.4490 - val_mean_absolute_error: 3.4490\n",
            "Epoch 55/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5109 - mean_absolute_error: 3.5109 - val_loss: 3.1884 - val_mean_absolute_error: 3.1884\n",
            "Epoch 56/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3248 - mean_absolute_error: 3.3248 - val_loss: 3.6540 - val_mean_absolute_error: 3.6540\n",
            "Epoch 57/100\n",
            "23/23 [==============================] - 0s 10ms/step - loss: 3.3570 - mean_absolute_error: 3.3570 - val_loss: 3.2961 - val_mean_absolute_error: 3.2961\n",
            "Epoch 58/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.7118 - mean_absolute_error: 3.7118 - val_loss: 3.7833 - val_mean_absolute_error: 3.7833\n",
            "Epoch 59/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4103 - mean_absolute_error: 3.4103 - val_loss: 4.1737 - val_mean_absolute_error: 4.1737\n",
            "Epoch 60/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4593 - mean_absolute_error: 3.4593 - val_loss: 3.1673 - val_mean_absolute_error: 3.1673\n",
            "Epoch 61/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1426 - mean_absolute_error: 3.1426 - val_loss: 3.7360 - val_mean_absolute_error: 3.7360\n",
            "Epoch 62/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6395 - mean_absolute_error: 3.6395 - val_loss: 4.6872 - val_mean_absolute_error: 4.6872\n",
            "Epoch 63/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.5619 - mean_absolute_error: 4.5619 - val_loss: 3.2708 - val_mean_absolute_error: 3.2708\n",
            "Epoch 64/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.4297 - mean_absolute_error: 3.4297 - val_loss: 3.7532 - val_mean_absolute_error: 3.7532\n",
            "Epoch 65/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.0403 - mean_absolute_error: 4.0403 - val_loss: 3.1093 - val_mean_absolute_error: 3.1093\n",
            "Epoch 66/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5319 - mean_absolute_error: 3.5319 - val_loss: 3.3979 - val_mean_absolute_error: 3.3979\n",
            "Epoch 67/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.3940 - mean_absolute_error: 3.3940 - val_loss: 5.0154 - val_mean_absolute_error: 5.0154\n",
            "Epoch 68/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 4.2372 - mean_absolute_error: 4.2372 - val_loss: 3.9615 - val_mean_absolute_error: 3.9615\n",
            "Epoch 69/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.1290 - mean_absolute_error: 3.1290 - val_loss: 3.0461 - val_mean_absolute_error: 3.0461\n",
            "Epoch 70/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.0881 - mean_absolute_error: 3.0881 - val_loss: 3.4425 - val_mean_absolute_error: 3.4425\n",
            "Epoch 71/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.4100 - mean_absolute_error: 3.4100 - val_loss: 5.1689 - val_mean_absolute_error: 5.1689\n",
            "Epoch 72/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.6334 - mean_absolute_error: 3.6334 - val_loss: 3.3653 - val_mean_absolute_error: 3.3653\n",
            "Epoch 73/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.9266 - mean_absolute_error: 3.9266 - val_loss: 4.6881 - val_mean_absolute_error: 4.6881\n",
            "Epoch 74/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.3414 - mean_absolute_error: 4.3414 - val_loss: 2.9656 - val_mean_absolute_error: 2.9656\n",
            "Epoch 75/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3457 - mean_absolute_error: 3.3457 - val_loss: 2.9394 - val_mean_absolute_error: 2.9394\n",
            "Epoch 76/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.9997 - mean_absolute_error: 2.9997 - val_loss: 2.9199 - val_mean_absolute_error: 2.9199\n",
            "Epoch 77/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5353 - mean_absolute_error: 3.5353 - val_loss: 3.9829 - val_mean_absolute_error: 3.9829\n",
            "Epoch 78/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.3817 - mean_absolute_error: 3.3817 - val_loss: 3.0714 - val_mean_absolute_error: 3.0714\n",
            "Epoch 79/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.4729 - mean_absolute_error: 3.4729 - val_loss: 5.7958 - val_mean_absolute_error: 5.7958\n",
            "Epoch 80/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 4.8310 - mean_absolute_error: 4.8310 - val_loss: 3.4110 - val_mean_absolute_error: 3.4110\n",
            "Epoch 81/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9297 - mean_absolute_error: 2.9297 - val_loss: 3.2227 - val_mean_absolute_error: 3.2227\n",
            "Epoch 82/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.2925 - mean_absolute_error: 3.2925 - val_loss: 3.8657 - val_mean_absolute_error: 3.8657\n",
            "Epoch 83/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5103 - mean_absolute_error: 3.5103 - val_loss: 3.0837 - val_mean_absolute_error: 3.0837\n",
            "Epoch 84/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9753 - mean_absolute_error: 2.9753 - val_loss: 3.1106 - val_mean_absolute_error: 3.1106\n",
            "Epoch 85/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9087 - mean_absolute_error: 2.9087 - val_loss: 3.2564 - val_mean_absolute_error: 3.2564\n",
            "Epoch 86/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.8239 - mean_absolute_error: 2.8239 - val_loss: 3.5455 - val_mean_absolute_error: 3.5455\n",
            "Epoch 87/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.1373 - mean_absolute_error: 3.1373 - val_loss: 3.0520 - val_mean_absolute_error: 3.0520\n",
            "Epoch 88/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.2666 - mean_absolute_error: 3.2666 - val_loss: 3.1752 - val_mean_absolute_error: 3.1752\n",
            "Epoch 89/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0598 - mean_absolute_error: 3.0598 - val_loss: 3.4714 - val_mean_absolute_error: 3.4714\n",
            "Epoch 90/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5936 - mean_absolute_error: 3.5936 - val_loss: 3.2603 - val_mean_absolute_error: 3.2603\n",
            "Epoch 91/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.3584 - mean_absolute_error: 3.3584 - val_loss: 3.4684 - val_mean_absolute_error: 3.4684\n",
            "Epoch 92/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 3.0457 - mean_absolute_error: 3.0457 - val_loss: 2.9521 - val_mean_absolute_error: 2.9521\n",
            "Epoch 93/100\n",
            "23/23 [==============================] - 0s 5ms/step - loss: 2.4955 - mean_absolute_error: 2.4955 - val_loss: 4.2829 - val_mean_absolute_error: 4.2829\n",
            "Epoch 94/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.3813 - mean_absolute_error: 3.3813 - val_loss: 3.0772 - val_mean_absolute_error: 3.0772\n",
            "Epoch 95/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.6761 - mean_absolute_error: 2.6761 - val_loss: 3.4871 - val_mean_absolute_error: 3.4871\n",
            "Epoch 96/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.5704 - mean_absolute_error: 3.5704 - val_loss: 2.9907 - val_mean_absolute_error: 2.9907\n",
            "Epoch 97/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9079 - mean_absolute_error: 2.9079 - val_loss: 2.9662 - val_mean_absolute_error: 2.9662\n",
            "Epoch 98/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.9291 - mean_absolute_error: 2.9291 - val_loss: 3.4009 - val_mean_absolute_error: 3.4009\n",
            "Epoch 99/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 2.7831 - mean_absolute_error: 2.7831 - val_loss: 2.9195 - val_mean_absolute_error: 2.9195\n",
            "Epoch 100/100\n",
            "23/23 [==============================] - 0s 6ms/step - loss: 3.0878 - mean_absolute_error: 3.0878 - val_loss: 3.0529 - val_mean_absolute_error: 3.0529\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f401a7e0cf8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t5q1WqDZm-xA"
      },
      "source": [
        "predictValues = nuralNetworkModel.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "id": "3uhl2YsgnD7O",
        "outputId": "a697992e-d2f7-426f-c7f6-38bc78d8c758"
      },
      "source": [
        "\r\n",
        "plt.scatter(Y_test,predictValues)\r\n",
        "from sklearn import metrics\r\n",
        "print('MAE:', metrics.mean_absolute_error(Y_test, predictValues))\r\n",
        "print('MSE:', metrics.mean_squared_error(Y_test, predictValues))\r\n",
        "print('RMSE:', np.sqrt(metrics.mean_squared_error(Y_test, predictValues)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MAE: 2.813615660182016\n",
            "MSE: 19.231791960952584\n",
            "RMSE: 4.385406704166967\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}